{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import xarray as xr\n",
    "import rioxarray as rio\n",
    "sys.path.append(os.path.abspath(\"c:\\\\Users\\\\m1865\\\\Desktop\\\\GIS Thesis Python\"))\n",
    "import mySTD\n",
    "# Data directory of ARPA data\n",
    "dd_arpa = \"c:\\\\Users\\\\m1865\\\\Desktop\\\\GIS Thesis Python\\\\ARPA\"\n",
    "dd_cams = \"c:\\\\Users\\\\m1865\\\\Desktop\\\\GIS Thesis Python\\\\CAMS\"\n",
    "dd_main = \"c:\\\\Users\\\\m1865\\\\Desktop\\\\GIS Thesis Python\"\n",
    "# Set current working directory\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myFile_NO2 = []\n",
    "myFile_O3 = []\n",
    "myFile_PM25 = []\n",
    "myFile_PM10 = []\n",
    "# Filter all the file names of the data from the data folder\n",
    "for filename in os.listdir(dd_cams):\n",
    "    match = re.match(r'(.*)2021(.*).nc', filename)\n",
    "    # print('Check Match')\n",
    "    if match:\n",
    "        # print('Matched!')\n",
    "        if match.group(1) == \"NO2\":\n",
    "            myFile_NO2.append(filename)\n",
    "        elif match.group(1) == \"ozone\":\n",
    "            myFile_O3.append(filename)\n",
    "        elif match.group(1) == \"PM25\": \n",
    "            myFile_PM25.append(filename)\n",
    "        elif match.group(1) == \"PM10\":\n",
    "            myFile_PM10.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList_NO2 = []\n",
    "myList_O3 = []\n",
    "myList_PM10 = []\n",
    "myList_PM25 = []\n",
    "for filename in myFile_NO2:\n",
    "    ds = xr.open_dataset(dd_cams + \"\\\\\" + filename)\n",
    "    newlong = mySTD.Lon360to180(ds)\n",
    "    newtime = mySTD.TimetoDate64(ds)\n",
    "    ds = ds.assign_coords(time=newtime,longitude=newlong).sortby(\"longitude\")\n",
    "    # print(ds.time.dt.month)\n",
    "    myList_NO2.append(ds)\n",
    "for filename in myFile_O3:\n",
    "    ds = xr.open_dataset(dd_cams + \"\\\\\" + filename)\n",
    "    newlong = mySTD.Lon360to180(ds)\n",
    "    newtime = mySTD.TimetoDate64(ds)\n",
    "    ds = ds.assign_coords(time=newtime,longitude=newlong).sortby(\"longitude\")\n",
    "    myList_O3.append(ds)\n",
    "for filename in myFile_PM10:\n",
    "    ds = xr.open_dataset(dd_cams + \"\\\\\" + filename)\n",
    "    newlong = mySTD.Lon360to180(ds)\n",
    "    newtime = mySTD.TimetoDate64(ds)\n",
    "    ds = ds.assign_coords(time=newtime,longitude=newlong).sortby(\"longitude\")\n",
    "    myList_PM10.append(ds)\n",
    "for filename in myFile_PM25:\n",
    "    ds = xr.open_dataset(dd_cams + \"\\\\\" + filename)\n",
    "    newlong = mySTD.Lon360to180(ds)\n",
    "    newtime = mySTD.TimetoDate64(ds)\n",
    "    ds = ds.assign_coords(time=newtime,longitude=newlong).sortby(\"longitude\")\n",
    "    myList_PM25.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "myList_NO2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList_NO2_Mean = []\n",
    "myList_O3_Mean = []\n",
    "myList_PM10_Mean = []\n",
    "myList_PM25_Mean = []\n",
    "for i in range(len(myList_NO2)):\n",
    "    ds = myList_NO2[i]\n",
    "    ds = ds.mean(dim='time')\n",
    "    ds = ds.mean(dim='level')\n",
    "    ds = ds.assign_attrs({\"month\": i+1})\n",
    "    myList_NO2_Mean.append(ds)\n",
    "for i in range(len(myList_O3)):\n",
    "    ds = myList_O3[i]\n",
    "    ds = ds.mean(dim='time')\n",
    "    ds = ds.mean(dim='level')\n",
    "    ds = ds.assign_attrs({\"month\": i+1})\n",
    "    myList_O3_Mean.append(ds)\n",
    "for i in range(len(myList_PM10)):\n",
    "    ds = myList_PM10[i]\n",
    "    ds = ds.mean(dim='time')\n",
    "    ds = ds.mean(dim='level')\n",
    "    ds = ds.assign_attrs({\"month\": i+1})\n",
    "    myList_PM10_Mean.append(ds)\n",
    "for i in range(len(myList_PM25)):\n",
    "    ds = myList_PM25[i]\n",
    "    ds = ds.mean(dim='time')\n",
    "    ds = ds.mean(dim='level')\n",
    "    ds = ds.assign_attrs({\"month\": i+1})\n",
    "    myList_PM25_Mean.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "myList_PM25_Mean[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lom = gpd.read_file('..\\lom.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList_NO2_Clipped = []\n",
    "myList_O3_Clipped = []\n",
    "myList_PM10_Clipped = []\n",
    "myList_PM25_Clipped = []\n",
    "for i in range(len(myList_NO2_Mean)):\n",
    "    ds = myList_NO2_Mean[i]\n",
    "    ds.rio.write_crs(4326, inplace=True)\n",
    "    ds = ds.rio.clip(lom.geometry, lom.crs, drop=True, invert = False)\n",
    "    myList_NO2_Clipped.append(ds)\n",
    "for i in range(len(myList_O3_Mean)):\n",
    "    ds = myList_O3_Mean[i]\n",
    "    ds.rio.write_crs(4326, inplace=True)\n",
    "    ds = ds.rio.clip(lom.geometry, lom.crs, drop=True, invert = False)\n",
    "    myList_O3_Clipped.append(ds)\n",
    "for i in range(len(myList_PM10_Mean)):\n",
    "    ds = myList_PM10_Mean[i]\n",
    "    ds.rio.write_crs(4326, inplace=True)\n",
    "    ds = ds.rio.clip(lom.geometry, lom.crs, drop=True, invert = False)\n",
    "    myList_PM10_Clipped.append(ds)\n",
    "for i in range(len(myList_PM25_Mean)):\n",
    "    ds = myList_PM25_Mean[i]\n",
    "    ds.rio.write_crs(4326, inplace=True)\n",
    "    ds = ds.rio.clip(lom.geometry, lom.crs, drop=True, invert = False)\n",
    "    myList_PM25_Clipped.append(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myList_NO2_Clipped[0].mean())\n",
    "myList_NO2_Clipped[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arpa_NO2 = pd.read_csv(cwd + \"\\\\ARPA NO2.csv\").round({'EST_UTM':-3,'NORD_UTM':-3})\n",
    "arpa_O3 = pd.read_csv(cwd + \"\\\\ARPA O3.csv\").round({'EST_UTM':-3,'NORD_UTM':-3})\n",
    "arpa_PM10 = pd.read_csv(cwd + \"\\\\ARPA PM10.csv\").round({'EST_UTM':-3,'NORD_UTM':-3})\n",
    "arpa_PM25 = pd.read_csv(cwd + \"\\\\ARPA PM25.csv\").round({'EST_UTM':-3,'NORD_UTM':-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average, variance, F-Test p value and T-Test p value for each pollutant, and the result for each one will be stored into a pandas dataframe. \n",
    "resultdf_NO2 = pd.DataFrame(columns=['Pollutant','Month','CAMS Average','ARPA Average','Average Residual','Relative Error','CAMS Variance','ARPA Variance','F-Test p Value','T-Test p Value'])\n",
    "resultdf_O3 = pd.DataFrame(columns=['Pollutant','Month','CAMS Average','ARPA Average','Average Residual','Relative Error','CAMS Variance','ARPA Variance','F-Test p Value','T-Test p Value'])\n",
    "resultdf_PM10 = pd.DataFrame(columns=['Pollutant','Month','CAMS Average','ARPA Average','Average Residual','Relative Error','CAMS Variance','ARPA Variance','F-Test p Value','T-Test p Value'])\n",
    "resultdf_PM25 = pd.DataFrame(columns=['Pollutant','Month','CAMS Average','ARPA Average','Average Residual','Relative Error','CAMS Variance','ARPA Variance','F-Test p Value','T-Test p Value'])\n",
    "resultdf_NO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "from scipy.stats import ttest_ind\n",
    "def f_test(x, y):\n",
    "    f = np.var(x, ddof=1)/np.var(y, ddof=1)\n",
    "    nun = x.size-1\n",
    "    dun = y.size-1\n",
    "    p_value = 1-scipy.stats.f.cdf(f, nun, dun)\n",
    "    return f, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO2\n",
    "for i in range(12):\n",
    "    df_Pollutant = 'NO2'\n",
    "    df_Month = i+1\n",
    "    df_Average = myList_NO2_Clipped[i].no2_conc.mean().data\n",
    "    df_Variance = myList_NO2_Clipped[i].no2_conc.std().data\n",
    "    df_UP_Average = arpa_NO2[arpa_NO2['Month']==(i+1)]['Valore'].mean()\n",
    "    df_UP_Variance = arpa_NO2[arpa_NO2['Month']==(i+1)]['Valore'].std()\n",
    "\n",
    "    df_cams = myList_NO2_Clipped[i].no2_conc.data\n",
    "    df_cams = df_cams[~np.isnan(df_cams)]\n",
    "    df_cams = df_cams.reshape(-1)\n",
    "    \n",
    "    df_camsup = arpa_NO2[arpa_NO2['Month']==(i+1)]['Valore']\n",
    "\n",
    "    df_FTest = f_test(df_cams,df_camsup)[1]\n",
    "    df_TTest = ttest_ind(df_cams,df_camsup)[1]\n",
    "    df_FTest = float(f\"{df_FTest:.6f}\")\n",
    "    df_TTest = float(f\"{df_TTest:.6f}\")\n",
    "\n",
    "    df_data = pd.DataFrame({\n",
    "        'Pollutant': [df_Pollutant], \n",
    "        'Month': [df_Month],\n",
    "        'CAMS Average': [df_Average],\n",
    "        'ARPA Average': [df_UP_Average],\n",
    "        'Average Residual': [df_Average-df_UP_Average],\n",
    "        'Relative Error': [(df_Average-df_UP_Average)/df_UP_Average],\n",
    "        'CAMS Variance': [df_Variance],\n",
    "        'ARPA Variance': [df_UP_Variance],\n",
    "        'F-Test p Value': [df_FTest],\n",
    "        'T-Test p Value': [df_TTest]\n",
    "    })\n",
    "    resultdf_NO2 = pd.concat([resultdf_NO2,df_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf_NO2 = resultdf_NO2.astype({'CAMS Average': float,'ARPA Average': float, 'Average Residual': float, 'CAMS Variance': float, 'ARPA Variance': float, 'F-Test p Value': float, 'T-Test p Value': float, 'Relative Error': float})\n",
    "resultdf_NO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "resultdf_NO2[['Month','CAMS Average','ARPA Average']].plot(x='Month', kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O3\n",
    "for i in range(12):\n",
    "    df_Pollutant = 'O3'\n",
    "    df_Month = i+1\n",
    "    df_Average = myList_O3_Clipped[i].o3_conc.mean().data\n",
    "    df_Variance = myList_O3_Clipped[i].o3_conc.std().data\n",
    "    df_UP_Average = arpa_O3[arpa_O3['Month']==(i+1)]['Valore'].mean()\n",
    "    df_UP_Variance = arpa_O3[arpa_O3['Month']==(i+1)]['Valore'].std()\n",
    "\n",
    "    df_cams = myList_O3_Clipped[i].o3_conc.data\n",
    "    df_cams = df_cams[~np.isnan(df_cams)]\n",
    "    df_cams = df_cams.reshape(-1)\n",
    "    \n",
    "    df_camsup = arpa_O3[arpa_O3['Month']==(i+1)]['Valore']\n",
    "\n",
    "    df_FTest = f_test(df_cams,df_camsup)[1]\n",
    "    df_TTest = ttest_ind(df_cams,df_camsup)[1]\n",
    "    df_FTest = float(f\"{df_FTest:.6f}\")\n",
    "    df_TTest = float(f\"{df_TTest:.6f}\")\n",
    "\n",
    "    df_data = pd.DataFrame({\n",
    "        'Pollutant': [df_Pollutant], \n",
    "        'Month': [df_Month],\n",
    "        'CAMS Average': [df_Average],\n",
    "        'ARPA Average': [df_UP_Average],\n",
    "        'Average Residual': [df_Average-df_UP_Average],\n",
    "        'Relative Error': [(df_Average-df_UP_Average)/df_UP_Average],\n",
    "        'CAMS Variance': [df_Variance],\n",
    "        'ARPA Variance': [df_UP_Variance],\n",
    "        'F-Test p Value': [df_FTest],\n",
    "        'T-Test p Value': [df_TTest]\n",
    "    })\n",
    "    resultdf_O3 = pd.concat([resultdf_O3,df_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf_O3 = resultdf_O3.astype({'CAMS Average': float,'ARPA Average': float, 'Average Residual': float, 'CAMS Variance': float, 'ARPA Variance': float, 'F-Test p Value': float, 'T-Test p Value': float, 'Relative Error': float})\n",
    "resultdf_O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "resultdf_O3[['Month','CAMS Average','ARPA Average']].plot(x='Month', kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PM10\n",
    "for i in range(12):\n",
    "    df_Pollutant = 'PM10'\n",
    "    df_Month = i+1\n",
    "    df_Average = myList_PM10_Clipped[i].pm10_conc.mean().data\n",
    "    df_Variance = myList_PM10_Clipped[i].pm10_conc.std().data\n",
    "    df_UP_Average = arpa_PM10[arpa_PM10['Month']==(i+1)]['Valore'].mean()\n",
    "    df_UP_Variance = arpa_PM10[arpa_PM10['Month']==(i+1)]['Valore'].std()\n",
    "\n",
    "    df_cams = myList_PM10_Clipped[i].pm10_conc.data\n",
    "    df_cams = df_cams[~np.isnan(df_cams)]\n",
    "    df_cams = df_cams.reshape(-1)\n",
    "    \n",
    "    df_camsup = arpa_PM10[arpa_PM10['Month']==(i+1)]['Valore']\n",
    "\n",
    "    df_FTest = f_test(df_cams,df_camsup)[1]\n",
    "    df_TTest = ttest_ind(df_cams,df_camsup)[1]\n",
    "    df_FTest = float(f\"{df_FTest:.6f}\")\n",
    "    df_TTest = float(f\"{df_TTest:.6f}\")\n",
    "\n",
    "    df_data = pd.DataFrame({\n",
    "        'Pollutant': [df_Pollutant], \n",
    "        'Month': [df_Month],\n",
    "        'CAMS Average': [df_Average],\n",
    "        'ARPA Average': [df_UP_Average],\n",
    "        'Average Residual': [df_Average-df_UP_Average],\n",
    "        'Relative Error': [(df_Average-df_UP_Average)/df_UP_Average],\n",
    "        'CAMS Variance': [df_Variance],\n",
    "        'ARPA Variance': [df_UP_Variance],\n",
    "        'F-Test p Value': [df_FTest],\n",
    "        'T-Test p Value': [df_TTest]\n",
    "    })\n",
    "    resultdf_PM10 = pd.concat([resultdf_PM10,df_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf_PM10 = resultdf_PM10.astype({'CAMS Average': float,'ARPA Average': float, 'Average Residual': float, 'CAMS Variance': float, 'ARPA Variance': float, 'F-Test p Value': float, 'T-Test p Value': float, 'Relative Error': float})\n",
    "resultdf_PM10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "resultdf_PM10[['Month','CAMS Average','ARPA Average']].plot(x='Month', kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PM25\n",
    "for i in range(12):\n",
    "    df_Pollutant = 'PM25'\n",
    "    df_Month = i+1\n",
    "    df_Average = myList_PM25_Clipped[i].pm2p5_conc.mean().data\n",
    "    df_Variance = myList_PM25_Clipped[i].pm2p5_conc.std().data\n",
    "    df_UP_Average = arpa_PM25[arpa_PM25['Month']==(i+1)]['Valore'].mean()\n",
    "    df_UP_Variance = arpa_PM25[arpa_PM25['Month']==(i+1)]['Valore'].std()\n",
    "\n",
    "    df_cams = myList_PM25_Clipped[i].pm2p5_conc.data\n",
    "    df_cams = df_cams[~np.isnan(df_cams)]\n",
    "    df_cams = df_cams.reshape(-1)\n",
    "    \n",
    "    df_camsup = arpa_PM25[arpa_PM25['Month']==(i+1)]['Valore']\n",
    "\n",
    "    df_FTest = f_test(df_cams,df_camsup)[1]\n",
    "    df_TTest = ttest_ind(df_cams,df_camsup)[1]\n",
    "    df_FTest = float(f\"{df_FTest:.6f}\")\n",
    "    df_TTest = float(f\"{df_TTest:.6f}\")\n",
    "\n",
    "    df_data = pd.DataFrame({\n",
    "        'Pollutant': [df_Pollutant], \n",
    "        'Month': [df_Month],\n",
    "        'CAMS Average': [df_Average],\n",
    "        'ARPA Average': [df_UP_Average],\n",
    "        'Average Residual': [df_Average-df_UP_Average],\n",
    "        'Relative Error': [(df_Average-df_UP_Average)/df_UP_Average],\n",
    "        'CAMS Variance': [df_Variance],\n",
    "        'ARPA Variance': [df_UP_Variance],\n",
    "        'F-Test p Value': [df_FTest],\n",
    "        'T-Test p Value': [df_TTest]\n",
    "    })\n",
    "    resultdf_PM25 = pd.concat([resultdf_PM25,df_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf_PM25 = resultdf_PM25.astype({'CAMS Average': float,'ARPA Average': float, 'Average Residual': float, 'CAMS Variance': float, 'ARPA Variance': float, 'F-Test p Value': float, 'T-Test p Value': float, 'Relative Error': float})\n",
    "resultdf_PM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "resultdf_PM25[['Month','CAMS Average','ARPA Average']].plot(x='Month', kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The numbers are all stored as object in the DataFrame. Conver them to the float with a precision of 6. \n",
    "# Create a dict for faster loop\n",
    "myDict = {\n",
    "    \"NO2\": resultdf_NO2,\n",
    "    \"O3\": resultdf_O3,\n",
    "    \"PM10\": resultdf_PM10,\n",
    "    \"PM25\": resultdf_PM25\n",
    "}\n",
    "myDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in myDict.values():\n",
    "    df['Average'] = df['Average'].astype(float).round(decimals=6)\n",
    "    df['Variance'] = df['Variance'].astype(float).round(decimals=6)\n",
    "    df['Upscale Average'] = df['Upscale Average'].astype(float).round(decimals=6)\n",
    "    df['Upscale Variance'] = df['Upscale Variance'].astype(float).round(decimals=6)\n",
    "    df['F-Test p Value'] = df['F-Test p Value'].astype(float).round(decimals=6)\n",
    "    df['T-Test p Value'] = df['T-Test p Value'].astype(float).round(decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf_PM25.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically export to excel file. Make sure the file is not open when overwriting existing one. \n",
    "# with pd.ExcelWriter('CAMS Upscale Model Tests.xlsx') as writer: \n",
    "#     resultdf_NO2.to_excel(writer, sheet_name='NO2', index=False)\n",
    "#     resultdf_O3.to_excel(writer, sheet_name='O3', index=False)\n",
    "#     resultdf_PM10.to_excel(writer, sheet_name='PM10', index=False)\n",
    "#     resultdf_PM25.to_excel(writer, sheet_name='PM2.5', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a single sheet for all the values. \n",
    "resultdf_combined_list = [resultdf_NO2, resultdf_O3, resultdf_PM25, resultdf_PM10]\n",
    "resultdf_combined = pd.concat(resultdf_combined_list)\n",
    "print(resultdf_combined)\n",
    "resultdf_combined.to_excel('CAMS Upscale Model Tests - AIO.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Django')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7afa1cb9a3c5ad40056603cb099f0b47ba2cafdea1c10862e45c5b18b0ff3b33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
