{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import xarray as xr\n",
    "import rioxarray as rio\n",
    "sys.path.append(os.path.abspath(\"c:\\\\Users\\\\m1865\\\\Desktop\\\\GIS Thesis Python\"))\n",
    "import mySTD\n",
    "# Data directory of ARPA data\n",
    "dd_arpa = \"c:\\\\Users\\\\m1865\\\\Desktop\\\\GIS Thesis Python\\\\ARPA\"\n",
    "dd_cams = \"c:\\\\Users\\\\m1865\\\\Desktop\\\\GIS Thesis Python\\\\CAMS\"\n",
    "dd_main = \"c:\\\\Users\\\\m1865\\\\Desktop\\\\GIS Thesis Python\"\n",
    "# Set current working directory\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myFile_NO2 = []\n",
    "myFile_O3 = []\n",
    "myFile_PM25 = []\n",
    "myFile_PM10 = []\n",
    "# Filter all the file names of the data from the data folder\n",
    "for filename in os.listdir(dd_cams):\n",
    "    match = re.match(r'(.*)2021(.*).nc', filename)\n",
    "    # print('Check Match')\n",
    "    if match:\n",
    "        # print('Matched!')\n",
    "        if match.group(1) == \"NO2\":\n",
    "            myFile_NO2.append(filename)\n",
    "        elif match.group(1) == \"ozone\":\n",
    "            myFile_O3.append(filename)\n",
    "        elif match.group(1) == \"PM25\": \n",
    "            myFile_PM25.append(filename)\n",
    "        elif match.group(1) == \"PM10\":\n",
    "            myFile_PM10.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList_NO2 = []\n",
    "myList_O3 = []\n",
    "myList_PM10 = []\n",
    "myList_PM25 = []\n",
    "for filename in myFile_NO2:\n",
    "    ds = xr.open_dataset(dd_cams + \"\\\\\" + filename)\n",
    "    newlong = mySTD.Lon360to180(ds)\n",
    "    newtime = mySTD.TimetoDate64(ds)\n",
    "    ds = ds.assign_coords(time=newtime,longitude=newlong).sortby(\"longitude\")\n",
    "    # print(ds.time.dt.month)\n",
    "    myList_NO2.append(ds)\n",
    "for filename in myFile_O3:\n",
    "    ds = xr.open_dataset(dd_cams + \"\\\\\" + filename)\n",
    "    newlong = mySTD.Lon360to180(ds)\n",
    "    newtime = mySTD.TimetoDate64(ds)\n",
    "    ds = ds.assign_coords(time=newtime,longitude=newlong).sortby(\"longitude\")\n",
    "    myList_O3.append(ds)\n",
    "for filename in myFile_PM10:\n",
    "    ds = xr.open_dataset(dd_cams + \"\\\\\" + filename)\n",
    "    newlong = mySTD.Lon360to180(ds)\n",
    "    newtime = mySTD.TimetoDate64(ds)\n",
    "    ds = ds.assign_coords(time=newtime,longitude=newlong).sortby(\"longitude\")\n",
    "    myList_PM10.append(ds)\n",
    "for filename in myFile_PM25:\n",
    "    ds = xr.open_dataset(dd_cams + \"\\\\\" + filename)\n",
    "    newlong = mySTD.Lon360to180(ds)\n",
    "    newtime = mySTD.TimetoDate64(ds)\n",
    "    ds = ds.assign_coords(time=newtime,longitude=newlong).sortby(\"longitude\")\n",
    "    myList_PM25.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "myList_NO2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList_NO2_Mean = []\n",
    "myList_O3_Mean = []\n",
    "myList_PM10_Mean = []\n",
    "myList_PM25_Mean = []\n",
    "for i in range(len(myList_NO2)):\n",
    "    ds = myList_NO2[i]\n",
    "    ds = ds.mean(dim='time')\n",
    "    ds = ds.mean(dim='level')\n",
    "    ds = ds.assign_attrs({\"month\": i+1})\n",
    "    myList_NO2_Mean.append(ds)\n",
    "for i in range(len(myList_O3)):\n",
    "    ds = myList_O3[i]\n",
    "    ds = ds.mean(dim='time')\n",
    "    ds = ds.mean(dim='level')\n",
    "    ds = ds.assign_attrs({\"month\": i+1})\n",
    "    myList_O3_Mean.append(ds)\n",
    "for i in range(len(myList_PM10)):\n",
    "    ds = myList_PM10[i]\n",
    "    ds = ds.mean(dim='time')\n",
    "    ds = ds.mean(dim='level')\n",
    "    ds = ds.assign_attrs({\"month\": i+1})\n",
    "    myList_PM10_Mean.append(ds)\n",
    "for i in range(len(myList_PM25)):\n",
    "    ds = myList_PM25[i]\n",
    "    ds = ds.mean(dim='time')\n",
    "    ds = ds.mean(dim='level')\n",
    "    ds = ds.assign_attrs({\"month\": i+1})\n",
    "    myList_PM25_Mean.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "myList_PM25_Mean[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lom = gpd.read_file('..\\lom.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList_NO2_Clipped = []\n",
    "myList_O3_Clipped = []\n",
    "myList_PM10_Clipped = []\n",
    "myList_PM25_Clipped = []\n",
    "for i in range(len(myList_NO2_Mean)):\n",
    "    ds = myList_NO2_Mean[i]\n",
    "    ds.rio.write_crs(4326, inplace=True)\n",
    "    ds = ds.rio.clip(lom.geometry, lom.crs, drop=True, invert = False)\n",
    "    myList_NO2_Clipped.append(ds)\n",
    "for i in range(len(myList_O3_Mean)):\n",
    "    ds = myList_O3_Mean[i]\n",
    "    ds.rio.write_crs(4326, inplace=True)\n",
    "    ds = ds.rio.clip(lom.geometry, lom.crs, drop=True, invert = False)\n",
    "    myList_O3_Clipped.append(ds)\n",
    "for i in range(len(myList_PM10_Mean)):\n",
    "    ds = myList_PM10_Mean[i]\n",
    "    ds.rio.write_crs(4326, inplace=True)\n",
    "    ds = ds.rio.clip(lom.geometry, lom.crs, drop=True, invert = False)\n",
    "    myList_PM10_Clipped.append(ds)\n",
    "for i in range(len(myList_PM25_Mean)):\n",
    "    ds = myList_PM25_Mean[i]\n",
    "    ds.rio.write_crs(4326, inplace=True)\n",
    "    ds = ds.rio.clip(lom.geometry, lom.crs, drop=True, invert = False)\n",
    "    myList_PM25_Clipped.append(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myList_NO2_Clipped[0].mean())\n",
    "myList_NO2_Clipped[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upscale CAMS\n",
    "myList_NO2_Clipped_Up = []\n",
    "myList_O3_Clipped_Up = []\n",
    "myList_PM10_Clipped_Up = []\n",
    "myList_PM25_Clipped_Up = []\n",
    "from geocube.api.core import make_geocube\n",
    "from geocube.rasterize import rasterize_points_griddata, rasterize_points_radial\n",
    "for i in range(len(myList_NO2_Clipped)):\n",
    "    ds = myList_NO2_Clipped[i].to_dataframe().reset_index()\n",
    "    ds = gpd.GeoDataFrame(ds.no2_conc,geometry=gpd.points_from_xy(ds.longitude,ds.latitude))\n",
    "    ds = ds.dropna()\n",
    "    ds = make_geocube(\n",
    "        vector_data=ds,\n",
    "        measurements=['no2_conc'],\n",
    "        resolution=(-0.01, 0.01),\n",
    "        rasterize_function=rasterize_points_griddata,\n",
    "    )\n",
    "    ds.rio.write_crs(4326, inplace=True)\n",
    "    upscale_clip = ds.rio.clip(lom.geometry, lom.crs, drop=True, invert = False)\n",
    "    myList_NO2_Clipped_Up.append(upscale_clip)\n",
    "for i in range(len(myList_O3_Clipped)):\n",
    "    ds = myList_O3_Clipped[i].to_dataframe().reset_index()\n",
    "    ds = gpd.GeoDataFrame(ds.o3_conc,geometry=gpd.points_from_xy(ds.longitude,ds.latitude))\n",
    "    ds = ds.dropna()\n",
    "    ds = make_geocube(\n",
    "        vector_data=ds,\n",
    "        measurements=['o3_conc'],\n",
    "        resolution=(-0.01, 0.01),\n",
    "        rasterize_function=rasterize_points_griddata,\n",
    "    )\n",
    "    ds.rio.write_crs(4326, inplace=True)\n",
    "    upscale_clip = ds.rio.clip(lom.geometry, lom.crs, drop=True, invert = False)\n",
    "    myList_O3_Clipped_Up.append(upscale_clip)\n",
    "for i in range(len(myList_PM10_Clipped)):\n",
    "    ds = myList_PM10_Clipped[i].to_dataframe().reset_index()\n",
    "    ds = gpd.GeoDataFrame(ds.pm10_conc,geometry=gpd.points_from_xy(ds.longitude,ds.latitude))\n",
    "    ds = ds.dropna()\n",
    "    ds = make_geocube(\n",
    "        vector_data=ds,\n",
    "        measurements=['pm10_conc'],\n",
    "        resolution=(-0.01, 0.01),\n",
    "        rasterize_function=rasterize_points_griddata,\n",
    "    )\n",
    "    ds.rio.write_crs(4326, inplace=True)\n",
    "    upscale_clip = ds.rio.clip(lom.geometry, lom.crs, drop=True, invert = False)\n",
    "    myList_PM10_Clipped_Up.append(upscale_clip)\n",
    "for i in range(len(myList_PM25_Clipped)):\n",
    "    ds = myList_PM25_Clipped[i].to_dataframe().reset_index()\n",
    "    ds = gpd.GeoDataFrame(ds.pm2p5_conc,geometry=gpd.points_from_xy(ds.longitude,ds.latitude))\n",
    "    ds = ds.dropna()\n",
    "    ds = make_geocube(\n",
    "        vector_data=ds,\n",
    "        measurements=['pm2p5_conc'],\n",
    "        resolution=(-0.01, 0.01),\n",
    "        rasterize_function=rasterize_points_griddata,\n",
    "    )\n",
    "    ds.rio.write_crs(4326, inplace=True)\n",
    "    upscale_clip = ds.rio.clip(lom.geometry, lom.crs, drop=True, invert = False)\n",
    "    myList_PM25_Clipped_Up.append(upscale_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average, variance, F-Test p value and T-Test p value for each pollutant, and the result for each one will be stored into a pandas dataframe. \n",
    "resultdf_NO2 = pd.DataFrame(columns=['Pollutant','Month','Average','Variance','Upscale Average','Upscale Variance','F-Test p Value','T-Test p Value'])\n",
    "resultdf_O3 = pd.DataFrame(columns=['Pollutant','Month','Average','Variance','Upscale Average','Upscale Variance','F-Test p Value','T-Test p Value'])\n",
    "resultdf_PM10 = pd.DataFrame(columns=['Pollutant','Month','Average','Variance','Upscale Average','Upscale Variance','F-Test p Value','T-Test p Value'])\n",
    "resultdf_PM25 = pd.DataFrame(columns=['Pollutant','Month','Average','Variance','Upscale Average','Upscale Variance','F-Test p Value','T-Test p Value'])\n",
    "resultdf_NO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "from scipy.stats import ttest_ind\n",
    "def f_test(x, y):\n",
    "    f = np.var(x, ddof=1)/np.var(y, ddof=1)\n",
    "    nun = x.size-1\n",
    "    dun = y.size-1\n",
    "    p_value = 1-scipy.stats.f.cdf(f, nun, dun)\n",
    "    return f, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO2\n",
    "for i in range(12):\n",
    "    df_Pollutant = 'NO2'\n",
    "    df_Month = i+1\n",
    "    df_Average = myList_NO2_Clipped[i].no2_conc.mean().data\n",
    "    df_Variance = myList_NO2_Clipped[i].no2_conc.std().data\n",
    "    df_UP_Average = myList_NO2_Clipped_Up[i].no2_conc.mean().data\n",
    "    df_UP_Variance = myList_NO2_Clipped_Up[i].no2_conc.std().data\n",
    "\n",
    "    df_cams = myList_NO2_Clipped[i].no2_conc.data\n",
    "    df_cams = df_cams[~np.isnan(df_cams)]\n",
    "    df_cams = df_cams.reshape(-1)\n",
    "    \n",
    "    df_camsup = myList_NO2_Clipped_Up[i].no2_conc.data\n",
    "    df_camsup = df_camsup[~np.isnan(df_camsup)]\n",
    "    df_camsup = df_camsup.reshape(-1)\n",
    "\n",
    "    df_FTest = f_test(df_cams,df_camsup)[1]\n",
    "    df_TTest = ttest_ind(df_cams,df_camsup)[1]\n",
    "\n",
    "    df_data = pd.DataFrame({\n",
    "        'Pollutant': [df_Pollutant], \n",
    "        'Month': [df_Month],\n",
    "        'Average': [df_Average],\n",
    "        'Variance': [df_Variance],\n",
    "        'Upscale Average': [df_UP_Average],\n",
    "        'Upscale Variance': [df_UP_Variance],\n",
    "        'F-Test p Value': [df_FTest],\n",
    "        'T-Test p Value': [df_TTest]\n",
    "    })\n",
    "    resultdf_NO2 = pd.concat([resultdf_NO2,df_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf_NO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O3\n",
    "for i in range(12):\n",
    "    df_Pollutant = 'O3'\n",
    "    df_Month = i+1\n",
    "    df_Average = myList_O3_Clipped[i].o3_conc.mean().data\n",
    "    df_Variance = myList_O3_Clipped[i].o3_conc.std().data\n",
    "    df_UP_Average = myList_O3_Clipped_Up[i].o3_conc.mean().data\n",
    "    df_UP_Variance = myList_O3_Clipped_Up[i].o3_conc.std().data\n",
    "\n",
    "    df_cams = myList_O3_Clipped[i].o3_conc.data\n",
    "    df_cams = df_cams[~np.isnan(df_cams)]\n",
    "    df_cams = df_cams.reshape(-1)\n",
    "    \n",
    "    df_camsup = myList_O3_Clipped_Up[i].o3_conc.data\n",
    "    df_camsup = df_camsup[~np.isnan(df_camsup)]\n",
    "    df_camsup = df_camsup.reshape(-1)\n",
    "\n",
    "    df_FTest = f_test(df_cams,df_camsup)[1]\n",
    "    df_TTest = ttest_ind(df_cams,df_camsup)[1]\n",
    "\n",
    "    df_data = pd.DataFrame({\n",
    "        'Pollutant': [df_Pollutant], \n",
    "        'Month': [df_Month],\n",
    "        'Average': [df_Average],\n",
    "        'Variance': [df_Variance],\n",
    "        'Upscale Average': [df_UP_Average],\n",
    "        'Upscale Variance': [df_UP_Variance],\n",
    "        'F-Test p Value': [df_FTest],\n",
    "        'T-Test p Value': [df_TTest]\n",
    "    })\n",
    "    resultdf_O3 = pd.concat([resultdf_O3,df_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf_O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PM10\n",
    "for i in range(12):\n",
    "    df_Pollutant = 'PM10'\n",
    "    df_Month = i+1\n",
    "    df_Average = myList_PM10_Clipped[i].pm10_conc.mean().data\n",
    "    df_Variance = myList_PM10_Clipped[i].pm10_conc.std().data\n",
    "    df_UP_Average = myList_PM10_Clipped_Up[i].pm10_conc.mean().data\n",
    "    df_UP_Variance = myList_PM10_Clipped_Up[i].pm10_conc.std().data\n",
    "\n",
    "    df_cams = myList_PM10_Clipped[i].pm10_conc.data\n",
    "    df_cams = df_cams[~np.isnan(df_cams)]\n",
    "    df_cams = df_cams.reshape(-1)\n",
    "    \n",
    "    df_camsup = myList_PM10_Clipped_Up[i].pm10_conc.data\n",
    "    df_camsup = df_camsup[~np.isnan(df_camsup)]\n",
    "    df_camsup = df_camsup.reshape(-1)\n",
    "\n",
    "    df_FTest = f_test(df_cams,df_camsup)[1]\n",
    "    df_TTest = ttest_ind(df_cams,df_camsup)[1]\n",
    "\n",
    "    df_data = pd.DataFrame({\n",
    "        'Pollutant': [df_Pollutant], \n",
    "        'Month': [df_Month],\n",
    "        'Average': [df_Average],\n",
    "        'Variance': [df_Variance],\n",
    "        'Upscale Average': [df_UP_Average],\n",
    "        'Upscale Variance': [df_UP_Variance],\n",
    "        'F-Test p Value': [df_FTest],\n",
    "        'T-Test p Value': [df_TTest]\n",
    "    })\n",
    "    resultdf_PM10 = pd.concat([resultdf_PM10,df_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf_PM10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PM25\n",
    "for i in range(12):\n",
    "    df_Pollutant = 'PM2.5'\n",
    "    df_Month = i+1\n",
    "    df_Average = myList_PM25_Clipped[i].pm2p5_conc.mean().data\n",
    "    df_Variance = myList_PM25_Clipped[i].pm2p5_conc.std().data\n",
    "    df_UP_Average = myList_PM25_Clipped_Up[i].pm2p5_conc.mean().data\n",
    "    df_UP_Variance = myList_PM25_Clipped_Up[i].pm2p5_conc.std().data\n",
    "\n",
    "    df_cams = myList_PM25_Clipped[i].pm2p5_conc.data\n",
    "    df_cams = df_cams[~np.isnan(df_cams)]\n",
    "    df_cams = df_cams.reshape(-1)\n",
    "    \n",
    "    df_camsup = myList_PM25_Clipped_Up[i].pm2p5_conc.data\n",
    "    df_camsup = df_camsup[~np.isnan(df_camsup)]\n",
    "    df_camsup = df_camsup.reshape(-1)\n",
    "\n",
    "    df_FTest = f_test(df_cams,df_camsup)[1]\n",
    "    df_TTest = ttest_ind(df_cams,df_camsup)[1]\n",
    "\n",
    "    df_data = pd.DataFrame({\n",
    "        'Pollutant': [df_Pollutant], \n",
    "        'Month': [df_Month],\n",
    "        'Average': [df_Average],\n",
    "        'Variance': [df_Variance],\n",
    "        'Upscale Average': [df_UP_Average],\n",
    "        'Upscale Variance': [df_UP_Variance],\n",
    "        'F-Test p Value': [df_FTest],\n",
    "        'T-Test p Value': [df_TTest]\n",
    "    })\n",
    "    resultdf_PM25 = pd.concat([resultdf_PM25,df_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf_PM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The numbers are all stored as object in the DataFrame. Conver them to the float with a precision of 6. \n",
    "# Create a dict for faster loop\n",
    "myDict = {\n",
    "    \"NO2\": resultdf_NO2,\n",
    "    \"O3\": resultdf_O3,\n",
    "    \"PM10\": resultdf_PM10,\n",
    "    \"PM25\": resultdf_PM25\n",
    "}\n",
    "myDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in myDict.values():\n",
    "    df['Average'] = df['Average'].astype(float).round(decimals=6)\n",
    "    df['Variance'] = df['Variance'].astype(float).round(decimals=6)\n",
    "    df['Upscale Average'] = df['Upscale Average'].astype(float).round(decimals=6)\n",
    "    df['Upscale Variance'] = df['Upscale Variance'].astype(float).round(decimals=6)\n",
    "    df['F-Test p Value'] = df['F-Test p Value'].astype(float).round(decimals=6)\n",
    "    df['T-Test p Value'] = df['T-Test p Value'].astype(float).round(decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf_PM25.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically export to excel file. Make sure the file is not open when overwriting existing one. \n",
    "# with pd.ExcelWriter('CAMS Upscale Model Tests.xlsx') as writer: \n",
    "#     resultdf_NO2.to_excel(writer, sheet_name='NO2', index=False)\n",
    "#     resultdf_O3.to_excel(writer, sheet_name='O3', index=False)\n",
    "#     resultdf_PM10.to_excel(writer, sheet_name='PM10', index=False)\n",
    "#     resultdf_PM25.to_excel(writer, sheet_name='PM2.5', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a single sheet for all the values. \n",
    "resultdf_combined_list = [resultdf_NO2, resultdf_O3, resultdf_PM25, resultdf_PM10]\n",
    "resultdf_combined = pd.concat(resultdf_combined_list)\n",
    "print(resultdf_combined)\n",
    "resultdf_combined.to_excel('CAMS Upscale Model Tests - AIO.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Django')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7afa1cb9a3c5ad40056603cb099f0b47ba2cafdea1c10862e45c5b18b0ff3b33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
